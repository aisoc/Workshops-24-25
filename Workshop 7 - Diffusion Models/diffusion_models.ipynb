{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d826c5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-17T13:43:30.600259Z",
     "iopub.status.busy": "2025-03-17T13:43:30.599945Z",
     "iopub.status.idle": "2025-03-17T15:43:00.707880Z",
     "shell.execute_reply": "2025-03-17T15:43:00.706625Z"
    },
    "papermill": {
     "duration": 7170.112959,
     "end_time": "2025-03-17T15:43:00.709531",
     "exception": false,
     "start_time": "2025-03-17T13:43:30.596572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35822 training images and 9765 test images.\n",
      "Training from scratch...\n",
      "===== Training Model from Scratch =====\n",
      "Epoch 1/50 | Step 0 | Loss: 1.0041\n",
      "Epoch 1/50 | Step 100 | Loss: 0.2530\n",
      "Epoch 1/50 | Step 200 | Loss: 0.1604\n",
      "Epoch 1/50 | Step 300 | Loss: 0.0952\n",
      "Epoch 1/50 | Step 400 | Loss: 0.1022\n",
      "Epoch 1/50 | Step 500 | Loss: 0.1106\n",
      "Epoch 2/50 | Step 0 | Loss: 0.0590\n",
      "Epoch 2/50 | Step 100 | Loss: 0.0733\n",
      "Epoch 2/50 | Step 200 | Loss: 0.0897\n",
      "Epoch 2/50 | Step 300 | Loss: 0.0706\n",
      "Epoch 2/50 | Step 400 | Loss: 0.0666\n",
      "Epoch 2/50 | Step 500 | Loss: 0.0500\n",
      "Epoch 3/50 | Step 0 | Loss: 0.0401\n",
      "Epoch 3/50 | Step 100 | Loss: 0.0425\n",
      "Epoch 3/50 | Step 200 | Loss: 0.0469\n",
      "Epoch 3/50 | Step 300 | Loss: 0.0416\n",
      "Epoch 3/50 | Step 400 | Loss: 0.0674\n",
      "Epoch 3/50 | Step 500 | Loss: 0.0443\n",
      "Epoch 4/50 | Step 0 | Loss: 0.0594\n",
      "Epoch 4/50 | Step 100 | Loss: 0.0440\n",
      "Epoch 4/50 | Step 200 | Loss: 0.0291\n",
      "Epoch 4/50 | Step 300 | Loss: 0.0715\n",
      "Epoch 4/50 | Step 400 | Loss: 0.0507\n",
      "Epoch 4/50 | Step 500 | Loss: 0.0372\n",
      "Epoch 5/50 | Step 0 | Loss: 0.0276\n",
      "Epoch 5/50 | Step 100 | Loss: 0.0682\n",
      "Epoch 5/50 | Step 200 | Loss: 0.0358\n",
      "Epoch 5/50 | Step 300 | Loss: 0.0379\n",
      "Epoch 5/50 | Step 400 | Loss: 0.0367\n",
      "Epoch 5/50 | Step 500 | Loss: 0.0428\n",
      "Epoch 6/50 | Step 0 | Loss: 0.0353\n",
      "Epoch 6/50 | Step 100 | Loss: 0.0298\n",
      "Epoch 6/50 | Step 200 | Loss: 0.0447\n",
      "Epoch 6/50 | Step 300 | Loss: 0.0430\n",
      "Epoch 6/50 | Step 400 | Loss: 0.0253\n",
      "Epoch 6/50 | Step 500 | Loss: 0.0176\n",
      "Epoch 7/50 | Step 0 | Loss: 0.0402\n",
      "Epoch 7/50 | Step 100 | Loss: 0.0548\n",
      "Epoch 7/50 | Step 200 | Loss: 0.0342\n",
      "Epoch 7/50 | Step 300 | Loss: 0.0405\n",
      "Epoch 7/50 | Step 400 | Loss: 0.0714\n",
      "Epoch 7/50 | Step 500 | Loss: 0.0416\n",
      "Epoch 8/50 | Step 0 | Loss: 0.0420\n",
      "Epoch 8/50 | Step 100 | Loss: 0.0262\n",
      "Epoch 8/50 | Step 200 | Loss: 0.0440\n",
      "Epoch 8/50 | Step 300 | Loss: 0.0401\n",
      "Epoch 8/50 | Step 400 | Loss: 0.0360\n",
      "Epoch 8/50 | Step 500 | Loss: 0.0548\n",
      "Epoch 9/50 | Step 0 | Loss: 0.0461\n",
      "Epoch 9/50 | Step 100 | Loss: 0.0368\n",
      "Epoch 9/50 | Step 200 | Loss: 0.0424\n",
      "Epoch 9/50 | Step 300 | Loss: 0.0623\n",
      "Epoch 9/50 | Step 400 | Loss: 0.0332\n",
      "Epoch 9/50 | Step 500 | Loss: 0.0411\n",
      "Epoch 10/50 | Step 0 | Loss: 0.0238\n",
      "Epoch 10/50 | Step 100 | Loss: 0.0396\n",
      "Epoch 10/50 | Step 200 | Loss: 0.0378\n",
      "Epoch 10/50 | Step 300 | Loss: 0.0340\n",
      "Epoch 10/50 | Step 400 | Loss: 0.0401\n",
      "Epoch 10/50 | Step 500 | Loss: 0.0451\n",
      "Epoch 11/50 | Step 0 | Loss: 0.0339\n",
      "Epoch 11/50 | Step 100 | Loss: 0.0406\n",
      "Epoch 11/50 | Step 200 | Loss: 0.0342\n",
      "Epoch 11/50 | Step 300 | Loss: 0.0475\n",
      "Epoch 11/50 | Step 400 | Loss: 0.0192\n",
      "Epoch 11/50 | Step 500 | Loss: 0.0311\n",
      "Epoch 12/50 | Step 0 | Loss: 0.0472\n",
      "Epoch 12/50 | Step 100 | Loss: 0.0426\n",
      "Epoch 12/50 | Step 200 | Loss: 0.0355\n",
      "Epoch 12/50 | Step 300 | Loss: 0.0444\n",
      "Epoch 12/50 | Step 400 | Loss: 0.0363\n",
      "Epoch 12/50 | Step 500 | Loss: 0.0308\n",
      "Epoch 13/50 | Step 0 | Loss: 0.0232\n",
      "Epoch 13/50 | Step 100 | Loss: 0.0221\n",
      "Epoch 13/50 | Step 200 | Loss: 0.0338\n",
      "Epoch 13/50 | Step 300 | Loss: 0.0391\n",
      "Epoch 13/50 | Step 400 | Loss: 0.0437\n",
      "Epoch 13/50 | Step 500 | Loss: 0.0312\n",
      "Epoch 14/50 | Step 0 | Loss: 0.0286\n",
      "Epoch 14/50 | Step 100 | Loss: 0.0426\n",
      "Epoch 14/50 | Step 200 | Loss: 0.0338\n",
      "Epoch 14/50 | Step 300 | Loss: 0.0234\n",
      "Epoch 14/50 | Step 400 | Loss: 0.0316\n",
      "Epoch 14/50 | Step 500 | Loss: 0.0206\n",
      "Epoch 15/50 | Step 0 | Loss: 0.0291\n",
      "Epoch 15/50 | Step 100 | Loss: 0.0538\n",
      "Epoch 15/50 | Step 200 | Loss: 0.0310\n",
      "Epoch 15/50 | Step 300 | Loss: 0.0260\n",
      "Epoch 15/50 | Step 400 | Loss: 0.0227\n",
      "Epoch 15/50 | Step 500 | Loss: 0.0278\n",
      "Epoch 16/50 | Step 0 | Loss: 0.0224\n",
      "Epoch 16/50 | Step 100 | Loss: 0.0216\n",
      "Epoch 16/50 | Step 200 | Loss: 0.0403\n",
      "Epoch 16/50 | Step 300 | Loss: 0.0473\n",
      "Epoch 16/50 | Step 400 | Loss: 0.0219\n",
      "Epoch 16/50 | Step 500 | Loss: 0.0205\n",
      "Epoch 17/50 | Step 0 | Loss: 0.0267\n",
      "Epoch 17/50 | Step 100 | Loss: 0.0417\n",
      "Epoch 17/50 | Step 200 | Loss: 0.0373\n",
      "Epoch 17/50 | Step 300 | Loss: 0.0164\n",
      "Epoch 17/50 | Step 400 | Loss: 0.0209\n",
      "Epoch 17/50 | Step 500 | Loss: 0.0437\n",
      "Epoch 18/50 | Step 0 | Loss: 0.0360\n",
      "Epoch 18/50 | Step 100 | Loss: 0.0387\n",
      "Epoch 18/50 | Step 200 | Loss: 0.0476\n",
      "Epoch 18/50 | Step 300 | Loss: 0.0439\n",
      "Epoch 18/50 | Step 400 | Loss: 0.0295\n",
      "Epoch 18/50 | Step 500 | Loss: 0.0373\n",
      "Epoch 19/50 | Step 0 | Loss: 0.0562\n",
      "Epoch 19/50 | Step 100 | Loss: 0.0227\n",
      "Epoch 19/50 | Step 200 | Loss: 0.0250\n",
      "Epoch 19/50 | Step 300 | Loss: 0.0270\n",
      "Epoch 19/50 | Step 400 | Loss: 0.0264\n",
      "Epoch 19/50 | Step 500 | Loss: 0.0423\n",
      "Epoch 20/50 | Step 0 | Loss: 0.0503\n",
      "Epoch 20/50 | Step 100 | Loss: 0.0431\n",
      "Epoch 20/50 | Step 200 | Loss: 0.0282\n",
      "Epoch 20/50 | Step 300 | Loss: 0.0217\n",
      "Epoch 20/50 | Step 400 | Loss: 0.0246\n",
      "Epoch 20/50 | Step 500 | Loss: 0.0458\n",
      "Epoch 21/50 | Step 0 | Loss: 0.0269\n",
      "Epoch 21/50 | Step 100 | Loss: 0.0286\n",
      "Epoch 21/50 | Step 200 | Loss: 0.0263\n",
      "Epoch 21/50 | Step 300 | Loss: 0.0226\n",
      "Epoch 21/50 | Step 400 | Loss: 0.0281\n",
      "Epoch 21/50 | Step 500 | Loss: 0.0357\n",
      "Epoch 22/50 | Step 0 | Loss: 0.0325\n",
      "Epoch 22/50 | Step 100 | Loss: 0.0237\n",
      "Epoch 22/50 | Step 200 | Loss: 0.0548\n",
      "Epoch 22/50 | Step 300 | Loss: 0.0415\n",
      "Epoch 22/50 | Step 400 | Loss: 0.0293\n",
      "Epoch 22/50 | Step 500 | Loss: 0.0285\n",
      "Epoch 23/50 | Step 0 | Loss: 0.0170\n",
      "Epoch 23/50 | Step 100 | Loss: 0.0366\n",
      "Epoch 23/50 | Step 200 | Loss: 0.0275\n",
      "Epoch 23/50 | Step 300 | Loss: 0.0247\n",
      "Epoch 23/50 | Step 400 | Loss: 0.0311\n",
      "Epoch 23/50 | Step 500 | Loss: 0.0497\n",
      "Epoch 24/50 | Step 0 | Loss: 0.0266\n",
      "Epoch 24/50 | Step 100 | Loss: 0.0371\n",
      "Epoch 24/50 | Step 200 | Loss: 0.0349\n",
      "Epoch 24/50 | Step 300 | Loss: 0.0174\n",
      "Epoch 24/50 | Step 400 | Loss: 0.0146\n",
      "Epoch 24/50 | Step 500 | Loss: 0.0309\n",
      "Epoch 25/50 | Step 0 | Loss: 0.0347\n",
      "Epoch 25/50 | Step 100 | Loss: 0.0266\n",
      "Epoch 25/50 | Step 200 | Loss: 0.0216\n",
      "Epoch 25/50 | Step 300 | Loss: 0.0196\n",
      "Epoch 25/50 | Step 400 | Loss: 0.0271\n",
      "Epoch 25/50 | Step 500 | Loss: 0.0427\n",
      "Epoch 26/50 | Step 0 | Loss: 0.0352\n",
      "Epoch 26/50 | Step 100 | Loss: 0.0260\n",
      "Epoch 26/50 | Step 200 | Loss: 0.0217\n",
      "Epoch 26/50 | Step 300 | Loss: 0.0314\n",
      "Epoch 26/50 | Step 400 | Loss: 0.0485\n",
      "Epoch 26/50 | Step 500 | Loss: 0.0419\n",
      "Epoch 27/50 | Step 0 | Loss: 0.0323\n",
      "Epoch 27/50 | Step 100 | Loss: 0.0331\n",
      "Epoch 27/50 | Step 200 | Loss: 0.0282\n",
      "Epoch 27/50 | Step 300 | Loss: 0.0282\n",
      "Epoch 27/50 | Step 400 | Loss: 0.0241\n",
      "Epoch 27/50 | Step 500 | Loss: 0.0168\n",
      "Epoch 28/50 | Step 0 | Loss: 0.0154\n",
      "Epoch 28/50 | Step 100 | Loss: 0.0316\n",
      "Epoch 28/50 | Step 200 | Loss: 0.0525\n",
      "Epoch 28/50 | Step 300 | Loss: 0.0251\n",
      "Epoch 28/50 | Step 400 | Loss: 0.0202\n",
      "Epoch 28/50 | Step 500 | Loss: 0.0167\n",
      "Epoch 29/50 | Step 0 | Loss: 0.0246\n",
      "Epoch 29/50 | Step 100 | Loss: 0.0188\n",
      "Epoch 29/50 | Step 200 | Loss: 0.0371\n",
      "Epoch 29/50 | Step 300 | Loss: 0.0315\n",
      "Epoch 29/50 | Step 400 | Loss: 0.0286\n",
      "Epoch 29/50 | Step 500 | Loss: 0.0201\n",
      "Epoch 30/50 | Step 0 | Loss: 0.0412\n",
      "Epoch 30/50 | Step 100 | Loss: 0.0236\n",
      "Epoch 30/50 | Step 200 | Loss: 0.0233\n",
      "Epoch 30/50 | Step 300 | Loss: 0.0201\n",
      "Epoch 30/50 | Step 400 | Loss: 0.0369\n",
      "Epoch 30/50 | Step 500 | Loss: 0.0414\n",
      "Epoch 31/50 | Step 0 | Loss: 0.0313\n",
      "Epoch 31/50 | Step 100 | Loss: 0.0177\n",
      "Epoch 31/50 | Step 200 | Loss: 0.0157\n",
      "Epoch 31/50 | Step 300 | Loss: 0.0318\n",
      "Epoch 31/50 | Step 400 | Loss: 0.0418\n",
      "Epoch 31/50 | Step 500 | Loss: 0.0217\n",
      "Epoch 32/50 | Step 0 | Loss: 0.0144\n",
      "Epoch 32/50 | Step 100 | Loss: 0.0286\n",
      "Epoch 32/50 | Step 200 | Loss: 0.0336\n",
      "Epoch 32/50 | Step 300 | Loss: 0.0398\n",
      "Epoch 32/50 | Step 400 | Loss: 0.0131\n",
      "Epoch 32/50 | Step 500 | Loss: 0.0364\n",
      "Epoch 33/50 | Step 0 | Loss: 0.0284\n",
      "Epoch 33/50 | Step 100 | Loss: 0.0211\n",
      "Epoch 33/50 | Step 200 | Loss: 0.0252\n",
      "Epoch 33/50 | Step 300 | Loss: 0.0288\n",
      "Epoch 33/50 | Step 400 | Loss: 0.0213\n",
      "Epoch 33/50 | Step 500 | Loss: 0.0308\n",
      "Epoch 34/50 | Step 0 | Loss: 0.0247\n",
      "Epoch 34/50 | Step 100 | Loss: 0.0304\n",
      "Epoch 34/50 | Step 200 | Loss: 0.0433\n",
      "Epoch 34/50 | Step 300 | Loss: 0.0342\n",
      "Epoch 34/50 | Step 400 | Loss: 0.0278\n",
      "Epoch 34/50 | Step 500 | Loss: 0.0262\n",
      "Epoch 35/50 | Step 0 | Loss: 0.0358\n",
      "Epoch 35/50 | Step 100 | Loss: 0.0264\n",
      "Epoch 35/50 | Step 200 | Loss: 0.0212\n",
      "Epoch 35/50 | Step 300 | Loss: 0.0333\n",
      "Epoch 35/50 | Step 400 | Loss: 0.0180\n",
      "Epoch 35/50 | Step 500 | Loss: 0.0291\n",
      "Epoch 36/50 | Step 0 | Loss: 0.0519\n",
      "Epoch 36/50 | Step 100 | Loss: 0.0237\n",
      "Epoch 36/50 | Step 200 | Loss: 0.0339\n",
      "Epoch 36/50 | Step 300 | Loss: 0.0438\n",
      "Epoch 36/50 | Step 400 | Loss: 0.0368\n",
      "Epoch 36/50 | Step 500 | Loss: 0.0246\n",
      "Epoch 37/50 | Step 0 | Loss: 0.0163\n",
      "Epoch 37/50 | Step 100 | Loss: 0.0136\n",
      "Epoch 37/50 | Step 200 | Loss: 0.0343\n",
      "Epoch 37/50 | Step 300 | Loss: 0.0197\n",
      "Epoch 37/50 | Step 400 | Loss: 0.0215\n",
      "Epoch 37/50 | Step 500 | Loss: 0.0476\n",
      "Epoch 38/50 | Step 0 | Loss: 0.0244\n",
      "Epoch 38/50 | Step 100 | Loss: 0.0308\n",
      "Epoch 38/50 | Step 200 | Loss: 0.0149\n",
      "Epoch 38/50 | Step 300 | Loss: 0.0220\n",
      "Epoch 38/50 | Step 400 | Loss: 0.0301\n",
      "Epoch 38/50 | Step 500 | Loss: 0.0184\n",
      "Epoch 39/50 | Step 0 | Loss: 0.0188\n",
      "Epoch 39/50 | Step 100 | Loss: 0.0235\n",
      "Epoch 39/50 | Step 200 | Loss: 0.0124\n",
      "Epoch 39/50 | Step 300 | Loss: 0.0183\n",
      "Epoch 39/50 | Step 400 | Loss: 0.0197\n",
      "Epoch 39/50 | Step 500 | Loss: 0.0443\n",
      "Epoch 40/50 | Step 0 | Loss: 0.0242\n",
      "Epoch 40/50 | Step 100 | Loss: 0.0307\n",
      "Epoch 40/50 | Step 200 | Loss: 0.0198\n",
      "Epoch 40/50 | Step 300 | Loss: 0.0283\n",
      "Epoch 40/50 | Step 400 | Loss: 0.0381\n",
      "Epoch 40/50 | Step 500 | Loss: 0.0423\n",
      "Epoch 41/50 | Step 0 | Loss: 0.0361\n",
      "Epoch 41/50 | Step 100 | Loss: 0.0185\n",
      "Epoch 41/50 | Step 200 | Loss: 0.0152\n",
      "Epoch 41/50 | Step 300 | Loss: 0.0285\n",
      "Epoch 41/50 | Step 400 | Loss: 0.0351\n",
      "Epoch 41/50 | Step 500 | Loss: 0.0284\n",
      "Epoch 42/50 | Step 0 | Loss: 0.0160\n",
      "Epoch 42/50 | Step 100 | Loss: 0.0241\n",
      "Epoch 42/50 | Step 200 | Loss: 0.0337\n",
      "Epoch 42/50 | Step 300 | Loss: 0.0198\n",
      "Epoch 42/50 | Step 400 | Loss: 0.0182\n",
      "Epoch 42/50 | Step 500 | Loss: 0.0347\n",
      "Epoch 43/50 | Step 0 | Loss: 0.0310\n",
      "Epoch 43/50 | Step 100 | Loss: 0.0295\n",
      "Epoch 43/50 | Step 200 | Loss: 0.0259\n",
      "Epoch 43/50 | Step 300 | Loss: 0.0339\n",
      "Epoch 43/50 | Step 400 | Loss: 0.0410\n",
      "Epoch 43/50 | Step 500 | Loss: 0.0460\n",
      "Epoch 44/50 | Step 0 | Loss: 0.0333\n",
      "Epoch 44/50 | Step 100 | Loss: 0.0167\n",
      "Epoch 44/50 | Step 200 | Loss: 0.0220\n",
      "Epoch 44/50 | Step 300 | Loss: 0.0227\n",
      "Epoch 44/50 | Step 400 | Loss: 0.0311\n",
      "Epoch 44/50 | Step 500 | Loss: 0.0252\n",
      "Epoch 45/50 | Step 0 | Loss: 0.0402\n",
      "Epoch 45/50 | Step 100 | Loss: 0.0245\n",
      "Epoch 45/50 | Step 200 | Loss: 0.0333\n",
      "Epoch 45/50 | Step 300 | Loss: 0.0203\n",
      "Epoch 45/50 | Step 400 | Loss: 0.0264\n",
      "Epoch 45/50 | Step 500 | Loss: 0.0246\n",
      "Epoch 46/50 | Step 0 | Loss: 0.0198\n",
      "Epoch 46/50 | Step 100 | Loss: 0.0234\n",
      "Epoch 46/50 | Step 200 | Loss: 0.0171\n",
      "Epoch 46/50 | Step 300 | Loss: 0.0251\n",
      "Epoch 46/50 | Step 400 | Loss: 0.0208\n",
      "Epoch 46/50 | Step 500 | Loss: 0.0220\n",
      "Epoch 47/50 | Step 0 | Loss: 0.0180\n",
      "Epoch 47/50 | Step 100 | Loss: 0.0202\n",
      "Epoch 47/50 | Step 200 | Loss: 0.0289\n",
      "Epoch 47/50 | Step 300 | Loss: 0.0253\n",
      "Epoch 47/50 | Step 400 | Loss: 0.0279\n",
      "Epoch 47/50 | Step 500 | Loss: 0.0288\n",
      "Epoch 48/50 | Step 0 | Loss: 0.0264\n",
      "Epoch 48/50 | Step 100 | Loss: 0.0199\n",
      "Epoch 48/50 | Step 200 | Loss: 0.0104\n",
      "Epoch 48/50 | Step 300 | Loss: 0.0243\n",
      "Epoch 48/50 | Step 400 | Loss: 0.0266\n",
      "Epoch 48/50 | Step 500 | Loss: 0.0264\n",
      "Epoch 49/50 | Step 0 | Loss: 0.0324\n",
      "Epoch 49/50 | Step 100 | Loss: 0.0190\n",
      "Epoch 49/50 | Step 200 | Loss: 0.0178\n",
      "Epoch 49/50 | Step 300 | Loss: 0.0169\n",
      "Epoch 49/50 | Step 400 | Loss: 0.0147\n",
      "Epoch 49/50 | Step 500 | Loss: 0.0198\n",
      "Epoch 50/50 | Step 0 | Loss: 0.0354\n",
      "Epoch 50/50 | Step 100 | Loss: 0.0211\n",
      "Epoch 50/50 | Step 200 | Loss: 0.0206\n",
      "Epoch 50/50 | Step 300 | Loss: 0.0354\n",
      "Epoch 50/50 | Step 400 | Loss: 0.0141\n",
      "Epoch 50/50 | Step 500 | Loss: 0.0226\n",
      "Final weights saved to /kaggle/working/latest_weights.pth\n",
      "Samples saved to samples/diffusion_samples.png\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# (Optional) Hide Pillow warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Palette images with Transparency\")\n",
    "\n",
    "##################################################\n",
    "# 1) Hyperparameters & Config\n",
    "##################################################\n",
    "\n",
    "T = 1000          # Diffusion steps\n",
    "beta_start = 0.0001\n",
    "beta_end   = 0.02\n",
    "\n",
    "epochs        = 50\n",
    "batch_size    = 64\n",
    "learning_rate = 1e-4\n",
    "image_size    = 32\n",
    "num_channels  = 3\n",
    "device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the beta/alpha schedules\n",
    "betas = torch.linspace(beta_start, beta_end, T).to(device)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alphas_cumprod_prev = torch.cat(\n",
    "    [torch.tensor([1.0], device=device), alphas_cumprod[:-1]], dim=0\n",
    ")\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "\n",
    "##################################################\n",
    "# 2) Define Forward Diffusion Function\n",
    "##################################################\n",
    "def forward_diffusion(x0, t):\n",
    "    \"\"\"\n",
    "    x0: [B, 3, H, W]  (clean images)\n",
    "    t:  [B]           (timesteps)\n",
    "    Returns: x_t, noise\n",
    "       x_t:   Noisy version of x0 at step t\n",
    "       noise: The actual noise added\n",
    "    \"\"\"\n",
    "    sqrt_alpha = sqrt_alphas_cumprod[t].reshape(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alpha = sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1, 1, 1)\n",
    "    noise = torch.randn_like(x0)\n",
    "    x_t = sqrt_alpha * x0 + sqrt_one_minus_alpha * noise\n",
    "    return x_t, noise\n",
    "\n",
    "##################################################\n",
    "# 3) Dataset Classes (Recursive Scanning)\n",
    "##################################################\n",
    "class PngDataset(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None, test_dir=None):\n",
    "        \"\"\"\n",
    "        root_dirs: list of directories to scan for images\n",
    "        transform: torchvision transforms\n",
    "        test_dir: directory whose .png images go into 'test_files'\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        self.test_files = []\n",
    "\n",
    "        # If a test_dir is specified, gather its images for the test set\n",
    "        if test_dir:\n",
    "            for folder, _, filenames in os.walk(test_dir):\n",
    "                for fname in filenames:\n",
    "                    if fname.lower().endswith(\".png\"):\n",
    "                        self.test_files.append(os.path.join(folder, fname))\n",
    "\n",
    "        # Gather all .png files from each root_dir\n",
    "        for root_dir in root_dirs:\n",
    "            for folder, _, filenames in os.walk(root_dir):\n",
    "                for fname in filenames:\n",
    "                    if fname.lower().endswith(\".png\"):\n",
    "                        full_path = os.path.join(folder, fname)\n",
    "                        # if test_dir is set, skip those paths here\n",
    "                        if test_dir and test_dir in full_path:\n",
    "                            continue\n",
    "                        self.files.append(full_path)\n",
    "\n",
    "        # Shuffle the big file list so we can do an 80/20 split\n",
    "        random.shuffle(self.files)\n",
    "\n",
    "        # 80% -> train_files, 20% -> test_files\n",
    "        split_idx = int(0.8 * len(self.files))\n",
    "        self.train_files = self.files[:split_idx]\n",
    "        # Extend the test_files array with the leftover 20%\n",
    "        self.test_files.extend(self.files[split_idx:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.train_files[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, 0  # dummy label\n",
    "\n",
    "class TestPngDataset(Dataset):\n",
    "    def __init__(self, test_files, transform=None):\n",
    "        self.test_files = test_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.test_files[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, 0  # dummy label\n",
    "\n",
    "##################################################\n",
    "# 4) U-Net Model (Predict Noise)\n",
    "##################################################\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified U-Net that doesn't take time embeddings.\n",
    "    It tries to predict noise given x.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = DoubleConv(3, 64)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.uptrans3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.uconv3   = DoubleConv(512, 256)\n",
    "        self.uptrans2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.uconv2   = DoubleConv(256, 128)\n",
    "        self.uptrans1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.uconv1   = DoubleConv(128, 64)\n",
    "        self.out_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No time embeddings: purely sees x\n",
    "        h1 = self.conv1(x)\n",
    "        h2 = self.conv2(self.pool(h1))\n",
    "        h3 = self.conv3(self.pool(h2))\n",
    "        h4 = self.conv4(self.pool(h3))\n",
    "\n",
    "        u3 = self.uptrans3(h4)\n",
    "        u3 = torch.cat([u3, h3], dim=1)\n",
    "        u3 = self.uconv3(u3)\n",
    "\n",
    "        u2 = self.uptrans2(u3)\n",
    "        u2 = torch.cat([u2, h2], dim=1)\n",
    "        u2 = self.uconv2(u2)\n",
    "\n",
    "        u1 = self.uptrans1(u2)\n",
    "        u1 = torch.cat([u1, h1], dim=1)\n",
    "        u1 = self.uconv1(u1)\n",
    "\n",
    "        return self.out_conv(u1)\n",
    "\n",
    "##################################################\n",
    "# 5) Instantiate Model & Optimizer\n",
    "##################################################\n",
    "model = UNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "##################################################\n",
    "# 6) Sample Function (Reverse Diffusion)\n",
    "##################################################\n",
    "@torch.no_grad()\n",
    "def sample_model(n=8):\n",
    "    \"\"\"\n",
    "    Generate n random samples using the learned noise predictor\n",
    "    in a DDPM-like reverse diffusion loop.\n",
    "    Saves the images as 'samples/diffusion_samples.png'\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.randn(n, 3, image_size, image_size, device=device)\n",
    "\n",
    "    # We do the standard DDPM sampling approach but\n",
    "    # the model doesn't take t, so we call model(x).\n",
    "    for i in reversed(range(T)):\n",
    "        beta_t = betas[i]\n",
    "        alpha_t = 1.0 - beta_t\n",
    "        alpha_t_bar = alphas_cumprod[i]\n",
    "        alpha_t_bar_prev = alphas_cumprod_prev[i] if i > 0 else torch.tensor(1.0, device=device)\n",
    "\n",
    "        # The model predicts noise\n",
    "        pred_noise = model(x)\n",
    "        # Equation 12 in DDPM\n",
    "        x = (1.0 / torch.sqrt(alpha_t)) * (\n",
    "            x - (beta_t / torch.sqrt(1.0 - alpha_t_bar)) * pred_noise\n",
    "        )\n",
    "\n",
    "        if i > 0:\n",
    "            sigma_t = math.sqrt(\n",
    "                (1.0 - alpha_t_bar_prev) / (1.0 - alpha_t_bar) * beta_t\n",
    "            )\n",
    "            noise = torch.randn_like(x)\n",
    "            x += sigma_t * noise\n",
    "\n",
    "    samples = x.cpu()\n",
    "    os.makedirs('samples', exist_ok=True)\n",
    "    out_path = 'samples/diffusion_samples.png'\n",
    "    img_grid = utils.make_grid(samples, nrow=4)\n",
    "    utils.save_image(img_grid, out_path)\n",
    "    print(f\"Samples saved to {out_path}\")\n",
    "\n",
    "##################################################\n",
    "# 7) Train Function (Saves Weights)\n",
    "##################################################\n",
    "def train_model():\n",
    "    print(\"===== Training Model from Scratch =====\")\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, (x0, _) in enumerate(train_loader):\n",
    "            x0 = x0.to(device)\n",
    "            t = torch.randint(0, T, (x0.shape[0],), device=device).long()\n",
    "\n",
    "            # forward diffusion\n",
    "            x_t, noise = forward_diffusion(x0, t)\n",
    "\n",
    "            # model predicts noise\n",
    "            noise_pred = model(x_t)\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} | Step {step} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Final save\n",
    "    torch.save(model.state_dict(), \"/kaggle/working/latest_weights.pth\", _use_new_zipfile_serialization=False)\n",
    "    print(\"Final weights saved to /kaggle/working/latest_weights.pth\")\n",
    "\n",
    "##################################################\n",
    "# 8) Dataset / DataLoader Setup\n",
    "##################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    # root_dirs -> where your training PNG files are\n",
    "    # test_dir -> a dedicated folder that must be in the test set\n",
    "    train_dirs = [\"/kaggle/input\"]\n",
    "    test_dir   = \"/kaggle/input/pokemon-images-and-types/images\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = PngDataset(root_dirs=train_dirs, transform=transform, test_dir=test_dir)\n",
    "    test_dataset = TestPngDataset(dataset.test_files, transform=transform)\n",
    "\n",
    "    # Quick checks\n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(\"Training dataset is empty. Check /kaggle/input for PNG images!\")\n",
    "    if len(test_dataset) == 0:\n",
    "        raise ValueError(\"Test dataset is empty. Check your test_dir for PNG images!\")\n",
    "\n",
    "    # Build loaders\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                              num_workers=2, pin_memory=True)\n",
    "\n",
    "    print(f\"Loaded {len(dataset)} training images and {len(test_dataset)} test images.\")\n",
    "\n",
    "    # Now ask user to load or retrain\n",
    "    weight_path = \"/kaggle/working/latest_weights.pth\"\n",
    "    #answer = input(\"Use existing weights (Y) or retrain (N)? \").strip().upper()\n",
    "\n",
    "    #if answer == \"Y\" and os.path.exists(weight_path):\n",
    "        #print(f\"Loading existing weights from {weight_path}...\")\n",
    "        # Because of PyTorch's future changes, specify weights_only=True\n",
    "        # plus _use_new_zipfile_serialization=False to be safe\n",
    "        #model.load_state_dict(torch.load(weight_path, map_location=device, weights_only=True))\n",
    "        # Sample\n",
    "        #sample_model(n=8)\n",
    "    #else:\n",
    "    print(\"Training from scratch...\")\n",
    "    train_model()\n",
    "    # Sample\n",
    "    sample_model(n=8)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50648479",
   "metadata": {
    "papermill": {
     "duration": 0.0138,
     "end_time": "2025-03-17T15:43:00.738295",
     "exception": false,
     "start_time": "2025-03-17T15:43:00.724495",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 28971,
     "sourceId": 36917,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 40205,
     "sourceId": 63131,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 973252,
     "sourceId": 1646333,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1166873,
     "sourceId": 1957871,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1475653,
     "sourceId": 2438548,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 92703,
     "sourceId": 7845681,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4688703,
     "sourceId": 7968725,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7174.404573,
   "end_time": "2025-03-17T15:43:02.381159",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-17T13:43:27.976586",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
